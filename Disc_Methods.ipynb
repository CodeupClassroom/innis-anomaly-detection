{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Methods (Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anomaly Detection:** Identification of items, events or observations which is significantly different from the remaining data.\n",
    "\n",
    "- Non-parametric approach\n",
    "- Frequency or counting based\n",
    "    - How many time a value of variable (e.g. ip address) shows up\n",
    "    - More frequent - less likely to be an anomaly\n",
    "    - less frequent - more likely to be an anomaly\n",
    "    - Calculate probability \n",
    "\n",
    "    \n",
    "- Conditional probability \n",
    "    $$ {P(A|B) = }\\frac{\\text{P(A U B)}}{\\text{P(B)}} $$\n",
    "    \n",
    "    \n",
    " Examples: \n",
    "- How many times we see an ip address in the dataset (count)\n",
    "- What is probability of ip address showing up in the dataset (ip count / total observations)\n",
    "- Conditional probability. Given an ip address, what is prob of a particular status(e.g authentication failure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes from the webserver logs of the API that we used in the timeseries module. Each row is one request to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'mysql+pymysql://{env.user}:{env.password}@{env.host}/logs'\n",
    "df = pd.read_sql('SELECT * FROM api_access', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to deal with parsing one entry in our log data\n",
    "def parse_log_entry(entry):\n",
    "    parts = entry.split()\n",
    "    output = {}\n",
    "    output['ip'] = parts[0]\n",
    "    output['timestamp'] = parts[3][1:].replace(':', ' ', 1)\n",
    "    output['request_method'] = parts[5][1:]\n",
    "    output['request_path'] = parts[6]\n",
    "    output['http_version'] = parts[7][:-1]\n",
    "    output['status_code'] = parts[8]\n",
    "    output['size'] = int(parts[9])\n",
    "    output['user_agent'] = ' '.join(parts[11:]).replace('\"', '')\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Synthetic data\n",
    "new = pd.DataFrame([\n",
    "    [\"95.31.18.119\", \"21/Apr/2019 10:02:41\", \"GET\", \"/api/v1/items/\", \"HTTP/1.1\", '200', 1153005, \"python-requests/2.21.0\"],\n",
    "    [\"95.31.16.121\", \"17/Apr/2019 19:36:41\", \"GET\", \"/api/v1/sales?page=79/\", \"HTTP/1.1\", '301', 1005, \"python-requests/2.21.0\"],\n",
    "    [\"97.105.15.120\", \"18/Apr/2019 19:42:41\", \"GET\", \"/api/v1/sales?page=79/\", \"HTTP/1.1\", '301', 2560, \"python-requests/2.21.0\"],\n",
    "    [\"97.105.19.58\", \"19/Apr/2019 19:42:41\", \"GET\", \"/api/v1/sales?page=79/\", \"HTTP/1.1\", '200', 2056327, \"python-requests/2.21.0\"],\n",
    "], columns=df.columns)\n",
    "\n",
    "df = df.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Anomalies in Discrete Variables\n",
    "\n",
    "- **count**: the number of times each unique value appears in the dataset\n",
    "- **frequencies**: the number of times each unique value appears in the dataset as a percentage of the total; the count divided by the total number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ip_df = pd.DataFrame(df.ip.value_counts(dropna=False)).reset_index().\\\n",
    "                rename(columns={'index': 'ip', 'ip': 'count'})\n",
    "ip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabity for each ip \n",
    "\n",
    "# ip_prob = count for each ip / total count in the dataframe\n",
    "\n",
    "ip_df2 = \n",
    "ip_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two data frames create above into a single one:\n",
    "ip_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can find how many unique ip addresses there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probabilities\n",
    "\n",
    "- What is probability of a certain status code given an IP address?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP Status Codes\n",
    "\n",
    "- 200: ok\n",
    "- 3xx: redirects\n",
    "- 4xx: client level errors -- the requester did something wrong\n",
    "- 5xx: server level errors -- the server did something wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob(A|B) = prob(A & B)/prob(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pab = \n",
    "Pb = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a particular ip, what is probability of a certain status code\n",
    "status_given_ip = \n",
    "status_given_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cases where the probability is < 100%\n",
    "* Status codes other than 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we use this if we are looking to apply assumptions on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add these probabilities to original events to detect anomalous events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
